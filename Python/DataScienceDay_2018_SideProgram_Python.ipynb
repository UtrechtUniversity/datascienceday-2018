{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data handling in Python \n",
    "\n",
    "Preparing and cleaning your data is an important step in every research. Messy data can adversely affect the outcome of your analysis. The preparation and cleaning step can be more time consuming than doing the actual analysis. It is also important to be able to reproduce the preparation and cleaning. This Data Science Day workshop provides an introduction to handling raw data with Python. It helps you to go from raw to clean data reproducibly.\n",
    "\n",
    "If needed, this workshop covers some of the basics of Python (modules, functions, lists, dicts). We will focus on data handling and when needed, we learn about Python. For a good introduction to the Python basics, we advise you to do one of the following online tutorials:\n",
    "\n",
    "- https://www.datacamp.com/courses/intro-to-python-for-data-science\n",
    "- https://www.tutorialspoint.com/python/index.htm\n",
    "- [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](https://books.google.nl/books?id=UiM3DwAAQBAJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What is Python?\n",
    "Python is an open source programming language. The Python language is relatively easy to learn and emphasises code readability. Python is used for a wide number of programming applications and is heavily used in scientific research. In recent years, the language gains popularity due to machine learning frameworks written in Python. The language was created by the Dutchman Guido van Rossum in 1991.\n",
    "\n",
    "To get a feeling for the design principles of the Python programming language, import the following easter egg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pandas\n",
    "Python has plenty of functions for data handling and wrangling. Nevertheless, the language has no built-in support for data frames or data tables like in R, Stata and Matlab. External frameworks can be used to make data handling easy and intuitive. The most popular frameworks are [Numpy](https://docs.scipy.org/doc/) and [Pandas](http://pandas.pydata.org/). Pandas is a high-level library that depends on Numpy. This workshop gives you an introduction into the pandas library. A good online resource to start working with `Pandas` is the [10 Minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html) guide.\n",
    "\n",
    "One can import the pandas framework in Python with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "On the internet, the `pandas` module is often imported in the following way:\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "This is only a rename to prevent writing 4 characters more each time... We don't use this notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 1. Import raw data and check data types\n",
    "\n",
    "In this step, we will import two (fictitious) medical datasets with patient data. To import the datasets with *pandas*, we need the path to the data file on the disk relative to this script. Pandas can be used to import all kind of data file formats like flat-text files, CSV files, Excel files and even SPSS and SAS data files. All functions that read data into memory start with [`pandas.read_`](https://pandas.pydata.org/pandas-docs/stable/api.html#input-output) followed by the data type. The first argument is the file location. \n",
    "\n",
    "In our case, we read `PatientDATA1.txt` and `PatientDATA2.txt` into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pandas.read_csv reads a character-delimited text file into a DataFrame object.\n",
    "\n",
    "# With '=' we assign the data to a variable name, so you can refer to the \n",
    "# data. We read in two files here that are related, we'll work with these \n",
    "# throughout this Jupyter notebook.\n",
    "\n",
    "df_pd1 = pandas.read_table(\"PatientDATA1.txt\")\n",
    "df_pd2 = pandas.read_csv(\"PatientDATA2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Question: What happens if you don't assign the data to a variable name?\n",
    "Answer:\n",
    "> Nothing is displayed by the interpreter after the entry, so it is not clear anything happened. Something has happened. This is an assignment statement, with a variable on the left. A variable is a name for a value. [Source](https://anh.cs.luc.edu/python/hands-on/3.1/handsonHtml/variables.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### DataFrame\n",
    "\n",
    "The variables `df_pd1` and `df_pd2` are `pandas.DataFrame` objects. A `pandas.DataFrame` is one of the two data structures in Pandas (the other structure is the `pandas.Series` structure). A DataFrame is a two dimensional, tabular data structure (like a spreadsheet). A DataFrame can hold different types of data; each column has it's own data type. For more information, read the pandas document on [data structures](https://pandas.pydata.org/pandas-docs/stable/dsintro.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first thing you do after you import the data is checking the data to see what you'll work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# open the help function for the object\n",
    "?df_pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The method 'head' gives you the first 5 rows of the DataFrame.\n",
    "df_pd1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "\n",
    "You've seen what method `.head()` does. Now check out `df_pd1` and `df_pd2` \n",
    "more closely with `.tail()`, `.describe()`, `.shape` and `.dtypes` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "\n",
    "You've seen what .head() and .tail() do. Instead of outputting the last \n",
    "5 lines, try to output the first 3 lines and the last 3 lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Select a DataFrame column (Series)\n",
    "\n",
    "Each column of the `df_pd1` and `df_pd2` can be extracted from the DataFrame. Pandas has several methods to do this. This two examples below show a good and a bad approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# return the column PATNO\n",
    "df_pd1[\"PATNO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# return the column PATNO as an attribute (not advised, why?)\n",
    "df_pd1.PATNO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 2. Change the column data types to appropriate ones\n",
    "\n",
    "All columns of a `pandas.DataFrame` have a *data type*. \n",
    "Each data type has its possibilities for analyses, and \n",
    "associated permitted values (value domain). For instance, 'two'\n",
    "is not a permitted value for a numeric data type, while '2' is.\n",
    "Similarly, you can't (and shouldn't) calculate with categorical data.\n",
    "So having assigned the correct data type gives you more possibilities \n",
    "and prevents mistakes.\n",
    "\n",
    "Pandas supports the following data types:\n",
    "\n",
    "- object (for text and Python objects)\n",
    "- float (for numerical)\n",
    "- int (for integers)\n",
    "- category (for categorical)\n",
    "- datetime (for dates) \n",
    "- bool (for True/False, or booleans)\n",
    "\n",
    "On can convert the data type of a column by replacing it with a converted column. This can be \n",
    "done with the method `.astype(...)`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd2[\"DX\"] = df_pd2[\"DX\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "\n",
    "Convert all columns of df_pd1 and df_pd2 to the right data type. If a `float` or `int` is not intended for calculations (such as the patient number), convert it to a factor.\n",
    "\n",
    "Dataset 1:\n",
    "\n",
    "- PATNO (patient ID): category \n",
    "- GENDER (gender): object\n",
    "- HR (heart rate): float \n",
    "- SBP_DBP (systolic_diastolic blood pressure): float \n",
    "- AE (got medicine yes/no): bool \n",
    "\n",
    "Dataset 2:\n",
    "\n",
    "- PATNO (patient ID): category \n",
    "- DX (diagnosis number): category \n",
    "- VISIT (date of visit): datetime\n",
    "\n",
    "> As a good practice, adjust the columns in a DataFrame to the correct class. Postpone this for some that you want to clean. i.e. Factors are easier manipulated as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# wipe\n",
    "\n",
    "df_pd1[\"PATNO\"] = df_pd1[\"PATNO\"].astype('category')\n",
    "df_pd1[\"GENDER\"] = df_pd1[\"GENDER\"].astype('object')\n",
    "df_pd1[\"HR\"] = df_pd1[\"HR\"].astype('float')\n",
    "df_pd1[\"SBP_DBP\"] = df_pd1[\"SBP_DBP\"].astype('object')\n",
    "df_pd1[\"AE\"] = df_pd1[\"AE\"].astype('bool')\n",
    "\n",
    "df_pd2[\"PATNO\"] = df_pd2[\"PATNO\"].astype('category')\n",
    "df_pd2[\"DX\"] = df_pd2[\"DX\"].astype('category')\n",
    "# df_pd2[\"VISIT\"] = df_pd2[\"VISIT\"].astype('datetime')\n",
    "\n",
    "df_pd2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert date columns\n",
    "\n",
    "Date and time values can't get converted with the `.astype()` method. Datetime values are converted with the function `pandas.to_datetime(...)`. Pandas converts the values into a computer-optimized `datetime` format. \n",
    "\n",
    "For the column VISIT, we want to convert the values into the international standard (year, month, day). These are indicated as %y (for short notation i.e. '16') or %Y (for long notation i.e. '2016'), %m, %d. Check out the official Python documentation for [all format codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dates formats are indicated as %y (short i.e. '09' or '9') or \n",
    "# %Y (long i.e. '2009'), %m (month as '04' or ; '4'), %d (day as '06' or '6').\n",
    "# Include how the date should be read with 'format'.\n",
    "pandas.to_datetime(df_pd2[\"VISIT\"], format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now really change the dataframe (by overwriting the column \"VISIT\")\n",
    "df_pd2[\"VISIT\"] = pandas.to_datetime(df_pd2[\"VISIT\"], format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now, the number of days between the visits can be calculated.\n",
    "# Possible now due to the correct datetime data type!\n",
    "df_pd2[\"VISIT\"].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 3. Integrate with other data\n",
    "For many research applications, there is a need to combine data from multiple datasets. Sometimes, the data needs to be merged vertically, but more often horizontally. For our two datasets, we would like to integrate the data about the patients and continue with one merged dataset (horizontally merged). Both datasets contain an identifier in common: PATNO. \n",
    "\n",
    "The `.merge(...)` method is very handy to merge the data horizontally. It enables you to \n",
    "\n",
    "- use the intersection of keys from both frames (`how=\"inner\"`) \n",
    "- use only the keys found in the left frame (`how=\"left\"`) \n",
    "- use only the keys found in the right frame (`how=\"right\"`) \n",
    "- use the union of keys from both frames and keep all data (`how=\"outer\"`) \n",
    "\n",
    "The following line of code gives you the help function of the `.merge` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "?pandas.DataFrame.merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "For our datasets, we merge on the common identifier 'PATNO'. We keep only the \n",
    "patients for which there is data in both files. What value for 'how' do you need \n",
    "to keep only the common patients between the files? As a good practice, do not \n",
    "overwrite the data objects that you've read in before. Assign a new name for your\n",
    "new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_pd = df_pd1.merge(df_pd2, on=, how=) \n",
    "\n",
    "# wipe\n",
    "df_pd = df_pd1.merge(df_pd2, on='PATNO', how='inner') \n",
    "\n",
    "df_pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "source": [
    "##### Question: How many rows and columns do the original files have? How many rows and columns does the new integrated file have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 4. Subselections of a DataFrame\n",
    "\n",
    "For analysis, you might want to work with a selection of the data. We have seen before how to select a column of a DataFrame. In this step, we explore more methods to select data of a DataFrame. We discuss the powerful `loc` and `iloc` attributes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# select multiple columns\n",
    "df_pd[[\"PATNO\", \"GENDER\", \"HR\", \"VISIT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "\n",
    "Split the code of the previous cell into two lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Selection by label\n",
    "\n",
    "The `.loc` attribute can be used to slice the data for both rows and columns by a label. The following code selects all rows (:) and the columns \"PATNO\", \"GENDER\", \"HR\" and \"VISIT\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd.loc[:, [\"PATNO\", \"GENDER\", \"HR\", \"VISIT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Selection by position\n",
    "\n",
    "The `.iloc` attribute can be used to slice the data both rows and columns by position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd.iloc[:, [0, 1, 2, 6]]\n",
    "\n",
    "# lists start at 0!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Assignment (boolean indexing)\n",
    "Select only the columns \"PATNO\", \"GENDER\", \"HR\" and \"VISIT\" for rows with a HR larger than 60. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 5. Operations on the data\n",
    "\n",
    "Pandas makes it easy to perform all kind of operations on the data. One can think of sorting, histogramming and sampling. But also all kind of statistics can be computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get frequencies of AE value\n",
    "# (1 and 8 occur at a different number: 4 and 3 times)\n",
    "df_pd[\"AE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Give frequencies of AE value separate for GENDER\n",
    "pandas.crosstab(df_pd[\"AE\"], df_pd[\"GENDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# take 3 random rows from the data\n",
    "df_pd.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Order the data on the heart rate\n",
    "df_pd.sort_values(\"HR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "\n",
    "Order the dataframe according to date of visit. Try to figure out what you\n",
    "can do with the arguments \"ascending\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_pd.sort_values(\"VISIT\", ascending=)\n",
    "\n",
    "# wipe\n",
    "df_pd.sort_values(\"VISIT\", ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "\n",
    "Is the sorting preserved? The answer is no. Try to preserve the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 6. Text/string data\n",
    "\n",
    "Columns with string data (what was the data type of string data?) can get manipulated with the powerful `str` (string) attribute. The `str` attribute can be used to lower, upper, split or strip strings. A good overview of what is possible can be found in the [Working with text data](https://pandas.pydata.org/pandas-docs/stable/text.html) tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd[\"GENDER\"].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For our data frame, we would like to add the systolic and diastolic blood pressure as two separate columns and remove the old. Then, we would like to compute the difference between these and also add it as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First separate SBP and DBP values on the underscore and expand it\n",
    "Pdata_SBP_DBP = df_pd[\"SBP_DBP\"].str.split(\"_\", expand=True)\n",
    "\n",
    "# Convert strings to integers\n",
    "Pdata_SBP_DBP = Pdata_SBP_DBP.astype(int)\n",
    "Pdata_SBP_DBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Pdata_SBP_DBP.columns = [\"SBP\", \"DBP\"]\n",
    "Pdata_SBP_DBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd_clean = pandas.concat([df_pd, Pdata_SBP_DBP], axis=1)\n",
    "df_pd_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove the old column\n",
    "df_pd_clean.drop(\"SBP_DBP\", axis=1, inplace=True)\n",
    "df_pd_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Assignment:\n",
    "Add a column to `df_pd_clean` named \"diff\" with the difference between DBP and SBP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 7. Make values consistent and remove outliers\n",
    "\n",
    "### Align vocabulary\n",
    "\n",
    "We take GENDER column for example. For GENDER, we see some inconsistencies. We know that in reality (for the larger part!) we have only two values for gender: Male and Female. Spelling mistakes or abbreviations can lead to many names for these. In this example, we show an effective, but slightly naive, way to clean this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check what GENDER column looks like.\n",
    "df_pd_clean[\"GENDER\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is a Python dict (dictonary)\n",
    "replace_dict = {\n",
    "    \"m\": \"Male\",\n",
    "    \"F\": \"Female\",\n",
    "    \"feminin\": \"Female\",\n",
    "    \"Mal\": \"Male\", \n",
    "    \"M\": \"Male\",\n",
    "    \"Man\": \"Male\"\n",
    "}\n",
    "\n",
    "# pass the replace dict to the `replace` method.\n",
    "df_pd_clean[\"GENDER_CLEAN\"] = df_pd_clean[\"GENDER\"].replace(replace_dict)\n",
    "\n",
    "df_pd_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd_clean[\"GENDER_CLEAN\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Assignment (advanced):\n",
    "\n",
    "The example above uses the replace method to align the vocabulary. For string data, one can also use the `str` attribute and regular expressions. Try to clean the \"GENDER\" column with regular expressions. Hint: `?pandas.Series.str.replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Remove (numeric) outliers\n",
    "\n",
    "Let's check if the numeric column values are within the expected value range. If not, we replace these values by `None` (missing value). In the following example, we remove measurement errors from the heart rate (HR) column. The value range should be between 40 and 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Maximum heart rate :', df_pd_clean[\"HR\"].max())\n",
    "print('Minimum heart rate :', df_pd_clean[\"HR\"].min())\n",
    "\n",
    "# The heart rate should have a value between 40 and 100. \n",
    "print('Mean heart rate :', df_pd_clean[\"HR\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Values outside of the realistic range should be omitted.\n",
    "\n",
    "df_pd_clean.loc[df_pd_clean[\"HR\"] < 40, \"HR\"] = None\n",
    "df_pd_clean.loc[df_pd_clean[\"HR\"] > 100, \"HR\"] = None\n",
    "\n",
    "df_pd_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Median heart rate :', df_pd_clean[\"HR\"].mean())\n",
    "# Notice how the mean of the Heart Rate (HR) has changed before\n",
    "# and after cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 8. Plot the data for inspection\n",
    "\n",
    "Visualising your data is one of the most powerful ways to explore and validate your data. Pandas can be used to visualize DataFrame columns directly. We will make a bar plot and a boxplot. Other ways to visualize data can be found in the [visualization tutorial](https://pandas.pydata.org/pandas-docs/stable/visualization.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This line of code is needed in older versions of Jupyter notebooks\n",
    "# to display plots.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pd_clean.plot.bar(\"PATNO\", \"HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_pd_clean[[\"HR\", \"SBP\", \"DBP\"]].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Ready for analyses!\n",
    "\n",
    "Now, the data is clean and you can start with analysing. For instance, is the difference in heart rate between Female and Male participants signifcant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.ttest_ind(\n",
    "    df_pd_clean.loc[df_pd_clean['GENDER_CLEAN'] == 'Male', 'HR'],\n",
    "    df_pd_clean.loc[df_pd_clean['GENDER_CLEAN'] == 'Female', 'HR'],\n",
    "    nan_policy='omit'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# End of the first part! \n",
    "This is the end of the first part of the introduction. In the next part, we will use an IDE on your local computer and work on the script out there. We will practice good formatting and commentting practices, such that others than you (or you yourself, in two months time) can easily understand your code. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
